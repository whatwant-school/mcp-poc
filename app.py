import asyncio
import nest_asyncio
import streamlit as st

from modules.llm_client import get_openai_response, get_gemini_response

nest_asyncio.apply()

# ì „ì—­ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


# Streamlit ì•±ì˜ í˜ì´ì§€ ì„¤ì • êµ¬ì„±
st.set_page_config(page_title="WHATWANT Chat", layout="wide")
st.title("ğŸ’¬ ì™€ë˜íŠ¸ ì±„íŒ… ë´‡")


# ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ì‚¬ì´ë“œë°”
model_name = st.sidebar.selectbox(
    "ğŸ§  ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    ["GPT-4", "GPT-3.5", "Gemini", "Custom-Bot"]
)

# í˜„ì¬ ì„ íƒëœ ëª¨ë¸ì„ ì‚¬ì´ë“œë°”ì— í‘œì‹œe
st.sidebar.markdown(f"í˜„ì¬ ì„ íƒëœ ëª¨ë¸: **{model_name}**")



# ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ëª¨ë“  ì´ì „ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


# ì±„íŒ… ì…ë ¥ ìƒìì—ì„œ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):

    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ì‘ë‹µ ìƒì„±
    if model_name == "Gemini":
        response = get_gemini_response(prompt)
    elif model_name == "GPT-4":
        response = get_openai_response(prompt, model="gpt-4")
    else:
        response = get_openai_response(prompt, model="gpt-3.5-turbo")

    # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
    st.session_state.chat_history.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
