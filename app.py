import os
from openai import OpenAI
import streamlit as st
import google.generativeai as genai

from dotenv import load_dotenv
load_dotenv()

# API í‚¤ ì„¤ì •
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Streamlit Chat", layout="centered")

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ ì„ íƒ
model_name = st.sidebar.selectbox(
    "ğŸ§  ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    ["GPT-4", "GPT-3.5", "Gemini", "Custom-Bot"]
)

st.sidebar.markdown(f"í˜„ì¬ ì„ íƒëœ ëª¨ë¸: **{model_name}**")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì œëª©
st.title("ğŸ’¬ ìŠ¤íŠ¸ë¦¼ë¦¿ ì±„íŒ… ë´‡")

# ì´ì „ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# GPT ì‘ë‹µ í•¨ìˆ˜
def get_openai_response(prompt, model="gpt-3.5-turbo"):
    try:
        response = openai_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"âŒ OpenAI ì˜¤ë¥˜: {e}"

# Gemini ì‘ë‹µ í•¨ìˆ˜
def get_gemini_response(prompt):
    try:
        model = genai.GenerativeModel("gemini-2.5-pro-exp-03-25")
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ Gemini ì˜¤ë¥˜: {e}"

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ìœ ì € ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # âœ… ëª¨ë¸ì— ë”°ë¼ ì‘ë‹µ ì²˜ë¦¬
    if model_name == "Gemini":
        response = get_gemini_response(prompt)
    elif model_name == "GPT-4":
        response = get_openai_response(prompt, model="gpt-4")
    else:  # GPT-3.5
        response = get_openai_response(prompt, model="gpt-3.5-turbo")

    # ì‘ë‹µ ì €ì¥ ë° ì¶œë ¥
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
